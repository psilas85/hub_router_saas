# hub_router_1.0.1/src/data_input/application/data_preprocessing.py
import locale

# ‚úÖ Ajuste robusto para suportar diferentes nomes de locale
for loc in ("pt_BR.UTF-8", "pt_BR.utf8", "C.UTF-8", "C"):
    try:
        locale.setlocale(locale.LC_ALL, loc)
        break
    except locale.Error:
        continue

import pandas as pd
import numpy as np
import logging
import os
import re
from typing import List
from data_input.config.config import UF_BOUNDS, CLUSTERING_CONFIG
from clusterization.domain.clustering_service import ClusteringService
from clusterization.domain.geolocalizacao_service import GeolocalizacaoService
from clusterization.domain.endereco_helper import EnderecoHelper
from clusterization.domain.entities import Entrega

logging.basicConfig(level=logging.INFO)


class DataPreprocessing:

    def __init__(self, writer, reader, tenant_id: str, path_saida_invalidos: str = None):
        self.writer = writer
        self.reader = reader
        self.tenant_id = tenant_id
        self.path_saida_invalidos = path_saida_invalidos or f"./tenants/{tenant_id}/output/registros_invalidos.csv"
        self.clustering_service = ClusteringService(UF_BOUNDS, CLUSTERING_CONFIG, reader, writer)
        self.geo_service = GeolocalizacaoService(reader, writer)

        self.mapeamento_colunas = {
            "Filial": "transportadora",
            "Remetente": "remetente_nome",
            "CNPJ/CPF": "remetente_cnpj",
            "Origem": "remetente_cidade",
            "UF Origem": "remetente_uf",
            "Destinat√°rio": "destinatario_nome",
            "CNPJ/CPF.1": "destinatario_cnpj",
            "Endere√ßo entrega": "cte_rua",
            "Bairro": "cte_bairro",
            "Complemento": "cte_complemento",
            "Cidade": "cte_cidade",
            "UF Entrega": "cte_uf",
            "CEP": "cte_cep",
            "NF": "cte_nf",
            "Volumes": "cte_volumes",
            "Kg Taxado": "cte_peso",
            "Valor NF": "cte_valor_nf",
            "Valor Frete": "cte_valor_frete",
            "Doc/Min": "doc_min",
            "Data Frete": "envio_data",
        }

    def execute(self, filepath, sep=","):
        try:
            df = self.carregar_dados(filepath, sep=sep)
            df = self.criar_cte_numero(df)
            df = self.criar_endereco_completo(df)
            df = self.formatar_dados(df)
            df = self.buscar_coordenadas(df)

            # üîç Salva registros com coordenadas fora da UF esperada
            if "coordenada_invalida" in df.columns:
                df_coord_invalidas = df[df["coordenada_invalida"] == True].copy()
                if not df_coord_invalidas.empty:
                    self.path_saida_coord_invalidas = f"./tenants/{self.tenant_id}/output/coordenadas_invalidas.csv"
                    os.makedirs(os.path.dirname(self.path_saida_coord_invalidas), exist_ok=True)
                    df_coord_invalidas.to_csv(self.path_saida_coord_invalidas, index=False, sep=";", encoding="utf-8-sig")
                    logging.warning(
                        f"üìç {len(df_coord_invalidas)} registro(s) com coordenadas fora da UF esperada salvos em: {self.path_saida_coord_invalidas}"
                    )

            df = self.validar_dados(df)

            if df.empty:
                logging.error("Nenhum dado v√°lido restante ap√≥s valida√ß√£o.")
                return None

            # ‚úÖ Prepara dados para inser√ß√£o no banco
            campos_entrega = Entrega.__init__.__code__.co_varnames[1:]
            if "tenant_id" not in campos_entrega:
                campos_entrega = list(campos_entrega) + ["tenant_id"]

            df["tenant_id"] = self.tenant_id
            df = df[[col for col in df.columns if col in campos_entrega]]

            entregas = [Entrega(**row) for row in df.to_dict(orient="records")]

            # üíæ Salva no banco
            self.writer.inserir_dados_entregas(entregas)
            self.writer.atualizar_data_processamento(entregas)

            logging.info(f"‚úÖ Processamento finalizado com {len(entregas)} registros v√°lidos.")
            return df, getattr(self, "qtde_invalidos", 0)

        except Exception as e:
            logging.error(f"‚ùå Erro ao executar pr√©-processamento: {e}", exc_info=True)
            return None

    def carregar_dados(self, filepath, sep=","):
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"Arquivo n√£o encontrado: {filepath}")

        df = pd.read_csv(filepath, sep=sep, encoding="utf-8-sig", dtype=str)

        # üîß Padroniza nomes das colunas
        df.columns = df.columns.str.strip()
        df.rename(columns=self.mapeamento_colunas, inplace=True)

        # ‚úÖ Convers√£o segura de campos num√©ricos
        def converter_coluna_valores(df, col):
            serie = df[col].astype(str).str.strip()
            padrao_americano = serie.str.contains(r"\d+,\d{3}\.\d{2}$")
            serie_formatada = serie.copy()
            serie_formatada[padrao_americano] = serie_formatada[padrao_americano].str.replace(",", "", regex=False)
            serie_formatada[~padrao_americano] = (
                serie_formatada[~padrao_americano]
                .str.replace(".", "", regex=False)
                .str.replace(",", ".", regex=False)
            )
            return pd.to_numeric(serie_formatada, errors="coerce")

        colunas_milhar = ["cte_valor_nf", "cte_valor_frete"]
        colunas_decimais = ["cte_peso", "cte_volumes"]

        for col in colunas_milhar + colunas_decimais:
            if col in df.columns:
                df[col] = converter_coluna_valores(df, col)

        # Limpa CNPJs
        for col in ["remetente_cnpj", "destinatario_cnpj"]:
            if col in df.columns:
                df[col] = df[col].astype(str).str.replace(r"[^0-9]", "", regex=True)

        # Convers√£o de data
        if "envio_data" in df.columns:
            df["envio_data"] = pd.to_datetime(df["envio_data"], dayfirst=True, errors="coerce").dt.date

        # Colunas geogr√°ficas extras obrigat√≥rias
        for col in ["cluster", "cluster_cidade", "cluster_endereco",
                    "centro_lat", "centro_lon", "destino_latitude", "destino_longitude"]:
            if col not in df.columns:
                df[col] = np.nan

        return df

    def criar_cte_numero(self, df):
        if "doc_min" in df.columns:
            df["cte_numero"] = df["doc_min"].astype(str).apply(lambda x: re.split(r"/", x)[0] if "/" in x else x)
        return df

    def criar_endereco_completo(self, df):
        df[["cte_rua", "cte_numero", "cte_cidade", "cte_uf"]] = df[
            ["cte_rua", "cte_numero", "cte_cidade", "cte_uf"]
        ].fillna("").astype(str)
        df["endereco_completo"] = df.apply(
            lambda x: EnderecoHelper.montar_endereco_completo(x["cte_rua"], x["cte_numero"], x["cte_cidade"], x["cte_uf"]),
            axis=1,
        )
        return df

    def buscar_coordenadas(self, df):
        """
        Busca coordenadas apenas para entregas sem latitude/longitude,
        aproveitando coordenadas j√° existentes no banco.
        """
        ignorados_por_uf = 0

        # üîç Busca cache no banco
        try:
            ctes = df["cte_numero"].dropna().unique().tolist()
            if ctes:
                df_cache = self.reader.buscar_latlon_ctes(
                    tenant_id=self.tenant_id,
                    lista_ctes=ctes
                )
                if not df_cache.empty:
                    df = df.merge(
                        df_cache[["cte_numero", "destino_latitude", "destino_longitude"]],
                        on="cte_numero",
                        how="left",
                        suffixes=("", "_db")
                    )
                    df["destino_latitude"] = df["destino_latitude"].combine_first(df["destino_latitude_db"])
                    df["destino_longitude"] = df["destino_longitude"].combine_first(df["destino_longitude_db"])
                    df.drop(columns=["destino_latitude_db", "destino_longitude_db"], inplace=True)
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Falha ao carregar cache de coordenadas do banco: {e}")

        # üéØ S√≥ os que continuam faltando
        df_faltando_coords = df[df["destino_latitude"].isna() | df["destino_longitude"].isna()]

        for idx, row in df_faltando_coords.iterrows():
            endereco = row["endereco_completo"]
            uf_esperada = row["cte_uf"]
            coordenadas = self.geo_service.buscar_coordenadas(endereco, uf_esperada)
            if coordenadas:
                df.at[idx, "destino_latitude"], df.at[idx, "destino_longitude"] = coordenadas
            else:
                ignorados_por_uf += 1
                df.at[idx, "coordenada_invalida"] = True

        self.registros_ignorados_uf = ignorados_por_uf
        return df

    def formatar_dados(self, df):
        for col in ["cte_peso", "cte_volumes", "cte_valor_nf", "cte_valor_frete"]:
            df[col] = df[col].astype(str).str.replace(",", ".").str.strip()
            df[col] = pd.to_numeric(df[col], errors="coerce")

        df["cte_cep"] = df["cte_cep"].astype(str).str.zfill(8)

        if "envio_data" in df.columns:
            df["envio_data"] = pd.to_datetime(df["envio_data"], errors="coerce", dayfirst=True).dt.date

        return df

    def validar_dados(self, df):
        colunas_obrigatorias = [
            "cte_numero", "cte_cidade", "cte_uf", "cte_cep",
            "cte_volumes", "cte_peso", "cte_valor_nf", "cte_valor_frete",
            "destino_latitude", "destino_longitude", "envio_data"
        ]

        # Normaliza vazios
        for col in colunas_obrigatorias:
            if col in df.columns:
                df[col] = df[col].replace({"": np.nan, "nan": np.nan, "None": np.nan})

        registros_invalidos = df[df[colunas_obrigatorias].isna().any(axis=1)].copy()

        def identificar_colunas_invalidas(row):
            faltantes = [col for col in colunas_obrigatorias if pd.isna(row[col])]
            return ", ".join(faltantes)

        if not registros_invalidos.empty:
            registros_invalidos["motivo_invalidade"] = registros_invalidos.apply(identificar_colunas_invalidas, axis=1)
            registros_invalidos.to_csv(self.path_saida_invalidos, index=False, encoding="utf-8-sig", sep=";")
            logging.warning(f"‚ö†Ô∏è {len(registros_invalidos)} registro(s) inv√°lido(s) salvos em: {self.path_saida_invalidos}")

        df_validos = df.dropna(subset=colunas_obrigatorias)

        if "coordenada_invalida" in df_validos.columns:
            removidos_coord = df_validos[df_validos["coordenada_invalida"] == True]
            if not removidos_coord.empty:
                logging.info(f"üóëÔ∏è {len(removidos_coord)} registro(s) removido(s) por coordenadas fora da UF esperada.")
            df_validos = df_validos[df_validos["coordenada_invalida"] != True]

        self.qtde_invalidos = len(registros_invalidos)
        return df_validos if df_validos is not None else pd.DataFrame()
